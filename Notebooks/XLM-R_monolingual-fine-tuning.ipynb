{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import statements","metadata":{}},{"cell_type":"code","source":"from datasets import get_dataset_config_names \nfrom datasets import load_dataset \nfrom collections import defaultdict\nfrom datasets import DatasetDict \nimport pandas as pd\nfrom collections import Counter \nfrom transformers import AutoTokenizer, XLMRobertaConfig, TrainingArguments, DataCollatorForTokenClassification, Trainer\nimport torch.nn as nn\nfrom transformers.modeling_outputs import TokenClassifierOutput\nfrom transformers.models.roberta.modeling_roberta import RobertaModel, RobertaPreTrainedModel \nimport torch\nimport numpy as np\n!pip install seqeval\nfrom seqeval.metrics import f1_score\nfrom torch.nn.functional import cross_entropy\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:01:25.305365Z","iopub.status.idle":"2025-01-03T00:01:25.305765Z","shell.execute_reply":"2025-01-03T00:01:25.305584Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset Loading & Investigating ","metadata":{}},{"cell_type":"code","source":"# Loading one of the PAN-X subsets (English, German, French, Italian) from XTREME Corpus\n\nxtreme_datasets = get_dataset_config_names(\"xtreme\")\nprint(f\"XTREME has {len(xtreme_datasets)} configurations\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:32:42.906306Z","iopub.execute_input":"2025-01-02T22:32:42.907454Z","iopub.status.idle":"2025-01-02T22:32:45.795316Z","shell.execute_reply.started":"2025-01-02T22:32:42.907430Z","shell.execute_reply":"2025-01-02T22:32:45.794426Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/131k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"916dde473f814b3a87ebc1f3f8d9765f"}},"metadata":{}},{"name":"stdout","text":"XTREME has 183 configurations\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Let’s narrow the search by just looking for the configurations that start with “PAN”\npanx_subsets = [subset for subset in xtreme_datasets if subset.startswith(\"PAN\")]\npanx_subsets[:3] ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:32:45.796987Z","iopub.execute_input":"2025-01-02T22:32:45.797213Z","iopub.status.idle":"2025-01-02T22:32:45.802588Z","shell.execute_reply.started":"2025-01-02T22:32:45.797195Z","shell.execute_reply":"2025-01-02T22:32:45.801641Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg']"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Crafting an imbalance swiss corpus\nlangs = [\"de\", \"fr\", \"it\", \"en\"] # [German, French, Italian, English] in ISO 639-1 language code\nfracs = [0.629, 0.229, 0.084, 0.059] # spoken proportion of each language in Switzerland\npanx_ch = defaultdict(DatasetDict) \n\nfor lang, frac in zip(langs, fracs):\n    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n    # Shuffle and downsample each split according to spoken proportion \n    for split in ds: \n        panx_ch[lang][split] = ds[split].shuffle(seed=0).select(range(int(frac * ds[split].num_rows)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:32:45.803887Z","iopub.execute_input":"2025-01-02T22:32:45.804183Z","iopub.status.idle":"2025-01-02T22:32:56.545218Z","shell.execute_reply.started":"2025-01-02T22:32:45.804154Z","shell.execute_reply":"2025-01-02T22:32:56.544610Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/1.18M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1d39bb024434d3480fcfa4a4e6fc145"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/590k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c721e5923b854596b7d4aeba3e74b7d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/588k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4aa7fbfbe8004da18e9779230fb4b83e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b62dccaa38a14dbeb3040459dea80e34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d987fa226be4dc4a80c8a35974a6e37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8af395e53c984c25b1e1ee40921d8e67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/837k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"585c28f1e0d84ffd95923742fc656616"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2886a0556ba84831b1df28f7f08a217e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/423k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9c8b345005443f28581207baa5a87b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41502fdac4dd49d1bb56a9c9385cd3ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9d345b15af340e58917364794fa0d87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1d74add737949e9bf91eb3381d6d152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/932k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc357a6fb0e408d92af1dbd8c3520fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/459k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1d7bb72d5bb4da686a4a27a82784cb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/464k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8cf88ccaab84d1fa920d8a07ecb00f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c30147a0051489bafce5be548628863"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d85f608d174940c7b1b80b9eb474ae23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86e0239dad8140d7be5b9ed0afb9c9d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/942k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04b635a47f944d22949ca08928dfe8a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/472k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae4e349187bb479b8a6d8dcf82bc8a48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/472k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"697bbd86f88c42a5bd357541f234113d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"800c1e6a67aa4525b0422d733d752fe2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6bb41e8f1a148cb86dd97c6d281ac37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5948911a718d47a2b3b26c025a4a118d"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"pd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs},\n            index=[\"Number of training examples\"]) # we have more examples in German than all other languages combined","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:32:56.545969Z","iopub.execute_input":"2025-01-02T22:32:56.546246Z","iopub.status.idle":"2025-01-02T22:32:56.562330Z","shell.execute_reply.started":"2025-01-02T22:32:56.546212Z","shell.execute_reply":"2025-01-02T22:32:56.561669Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                de    fr    it    en\nNumber of training examples  12580  4580  1680  1180","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>de</th>\n      <th>fr</th>\n      <th>it</th>\n      <th>en</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Number of training examples</th>\n      <td>12580</td>\n      <td>4580</td>\n      <td>1680</td>\n      <td>1180</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"entry = panx_ch[\"de\"][\"train\"][0]\nfor key, value in entry.items():\n    print(f\"{key}: {value}\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:32:56.563331Z","iopub.execute_input":"2025-01-02T22:32:56.563619Z","iopub.status.idle":"2025-01-02T22:32:56.579527Z","shell.execute_reply.started":"2025-01-02T22:32:56.563550Z","shell.execute_reply":"2025-01-02T22:32:56.578727Z"}},"outputs":[{"name":"stdout","text":"tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\nner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\nlangs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"for key, value in panx_ch[\"de\"][\"train\"].features.items():\n    print(f\"{key}: {value}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:32:56.580465Z","iopub.execute_input":"2025-01-02T22:32:56.580792Z","iopub.status.idle":"2025-01-02T22:32:56.593068Z","shell.execute_reply.started":"2025-01-02T22:32:56.580763Z","shell.execute_reply":"2025-01-02T22:32:56.592163Z"}},"outputs":[{"name":"stdout","text":"tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\nner_tags: Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\nlangs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\nprint(tags) # will be used for deciphering the ner_tags labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:32:56.595767Z","iopub.execute_input":"2025-01-02T22:32:56.595984Z","iopub.status.idle":"2025-01-02T22:32:56.611033Z","shell.execute_reply.started":"2025-01-02T22:32:56.595966Z","shell.execute_reply":"2025-01-02T22:32:56.610148Z"}},"outputs":[{"name":"stdout","text":"ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"tags.int2str(3) # converting the indices into strings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:32:56.612712Z","iopub.execute_input":"2025-01-02T22:32:56.612896Z","iopub.status.idle":"2025-01-02T22:32:56.625774Z","shell.execute_reply.started":"2025-01-02T22:32:56.612880Z","shell.execute_reply":"2025-01-02T22:32:56.625128Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'B-ORG'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"def create_tag_names(batch):\n    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:32:56.626536Z","iopub.execute_input":"2025-01-02T22:32:56.626802Z","iopub.status.idle":"2025-01-02T22:32:56.640316Z","shell.execute_reply.started":"2025-01-02T22:32:56.626771Z","shell.execute_reply":"2025-01-02T22:32:56.639503Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"panx_de = panx_ch[\"de\"].map(create_tag_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:32:56.641145Z","iopub.execute_input":"2025-01-02T22:32:56.641445Z","iopub.status.idle":"2025-01-02T22:32:59.454197Z","shell.execute_reply.started":"2025-01-02T22:32:56.641414Z","shell.execute_reply":"2025-01-02T22:32:59.453222Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12580 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a82e02d4c0fc4595b8841fa740d91b4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6290 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cb7acc2bab3436192046a0c6594fcc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6290 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ad8238f2f044953b6b4a477b000da83"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"de_example = panx_de[\"train\"][0]\npd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]],\n['Tokens', 'Tags'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:32:59.454954Z","iopub.execute_input":"2025-01-02T22:32:59.455235Z","iopub.status.idle":"2025-01-02T22:32:59.467475Z","shell.execute_reply.started":"2025-01-02T22:32:59.455212Z","shell.execute_reply":"2025-01-02T22:32:59.466287Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"           0           1   2    3         4      5   6    7           8   \\\nTokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \nTags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n\n                  9        10 11  \nTokens  Woiwodschaft  Pommern  .  \nTags           B-LOC    I-LOC  O  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>2.000</td>\n      <td>Einwohnern</td>\n      <td>an</td>\n      <td>der</td>\n      <td>Danziger</td>\n      <td>Bucht</td>\n      <td>in</td>\n      <td>der</td>\n      <td>polnischen</td>\n      <td>Woiwodschaft</td>\n      <td>Pommern</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":" As a quick check that we don’t have any unusual imbalance in the tags, let’s calculate the frequencies of each\n entity across each split","metadata":{}},{"cell_type":"code","source":"split2freq = defaultdict(Counter)\nfor split, dataset in panx_de.items():\n    for row in dataset[\"ner_tags_str\"]:\n        for tag in row:\n            if tag.startswith(\"B\"):\n                tag_type = tag.split(\"-\")[1]\n                split2freq[split][tag_type] += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:32:59.468355Z","iopub.execute_input":"2025-01-02T22:32:59.468658Z","iopub.status.idle":"2025-01-02T22:32:59.796232Z","shell.execute_reply.started":"2025-01-02T22:32:59.468625Z","shell.execute_reply":"2025-01-02T22:32:59.795638Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"pd.DataFrame.from_dict(split2freq, orient=\"index\") # over the same set, we have balance of labels across each split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:32:59.796967Z","iopub.execute_input":"2025-01-02T22:32:59.797190Z","iopub.status.idle":"2025-01-02T22:32:59.804872Z","shell.execute_reply.started":"2025-01-02T22:32:59.797171Z","shell.execute_reply":"2025-01-02T22:32:59.804030Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"             LOC   ORG   PER\ntrain       6186  5366  5810\nvalidation  3172  2683  2893\ntest        3180  2573  3071","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LOC</th>\n      <th>ORG</th>\n      <th>PER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>train</th>\n      <td>6186</td>\n      <td>5366</td>\n      <td>5810</td>\n    </tr>\n    <tr>\n      <th>validation</th>\n      <td>3172</td>\n      <td>2683</td>\n      <td>2893</td>\n    </tr>\n    <tr>\n      <th>test</th>\n      <td>3180</td>\n      <td>2573</td>\n      <td>3071</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"This looks good—the distributions of the PER, LOC, and ORG frequencies are roughly the same for each split, so\n the validation and test sets should provide a good measure of our NER tagger’s ability to generalize.","metadata":{}},{"cell_type":"markdown","source":"## Multilingual Transformer XLM-RoBERTa (XLM-R)","metadata":{}},{"cell_type":"markdown","source":"### SentencePiece (XLM-R) VS SentencePiece (BERT)","metadata":{}},{"cell_type":"code","source":"bert_model_name = \"bert-base-cased\"\nxlmr_model_name = \"xlm-roberta-base\"\nbert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\nxlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:32:59.805851Z","iopub.execute_input":"2025-01-02T22:32:59.806123Z","iopub.status.idle":"2025-01-02T22:33:02.691854Z","shell.execute_reply.started":"2025-01-02T22:32:59.806095Z","shell.execute_reply":"2025-01-02T22:33:02.690826Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c920d8d0cfd7430c9bd1f1661ba8dae0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6e0eba4c4c840da9024ef82393bc8f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cbb440886aa40f7a4679a583db15f83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ca3a6d335fa432886a3253cbd138e72"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db8bf4bc211d4d4eabb7c4973dd8318d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13a560aea06c40b292168bed48980f4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"245f66cafdf54cb79737778493727fa2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b6dc09b8b4143a985f5369c5390832f"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":" text = \"Jack Sparrow loves New York!\"\n bert_tokens = bert_tokenizer(text).tokens()\n xlmr_tokens = xlmr_tokenizer(text).tokens()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:02.692755Z","iopub.execute_input":"2025-01-02T22:33:02.692995Z","iopub.status.idle":"2025-01-02T22:33:02.699068Z","shell.execute_reply.started":"2025-01-02T22:33:02.692974Z","shell.execute_reply":"2025-01-02T22:33:02.698397Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(bert_tokens)\nprint(xlmr_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:02.699674Z","iopub.execute_input":"2025-01-02T22:33:02.699867Z","iopub.status.idle":"2025-01-02T22:33:02.716030Z","shell.execute_reply.started":"2025-01-02T22:33:02.699850Z","shell.execute_reply":"2025-01-02T22:33:02.715350Z"}},"outputs":[{"name":"stdout","text":"['[CLS]', 'Jack', 'Spa', '##rrow', 'loves', 'New', 'York', '!', '[SEP]']\n['<s>', '▁Jack', '▁Spar', 'row', '▁love', 's', '▁New', '▁York', '!', '</s>']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":" Here we see that instead of the `[CLS]` and `[SEP]` tokens that BERT uses for sentence classification tasks, XLM\nR uses `<s>` and `<\\s>` to denote the start and end of a sequence. `▁` this character refers to the whitesapce between tokens.","metadata":{}},{"cell_type":"code","source":" \"\".join(xlmr_tokens).replace(u\"\\u2581\", \" \") # the '▁' refers to the present of absence of whitespace, making the detokenizing step is applicable.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:02.716812Z","iopub.execute_input":"2025-01-02T22:33:02.716993Z","iopub.status.idle":"2025-01-02T22:33:02.732971Z","shell.execute_reply.started":"2025-01-02T22:33:02.716978Z","shell.execute_reply":"2025-01-02T22:33:02.732278Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'<s> Jack Sparrow loves New York!</s>'"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":" ### Transformers for Named Entity Recognition","metadata":{}},{"cell_type":"code","source":"class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n    config_class = XLMRobertaConfig\n    def __init__(self, config):\n        super().__init__(config)\n        self.num_labels = config.num_labels\n        # uploading the model\n        self.roberta = RobertaModel(config, add_pooling_layer=False) # by disabling the pooling parameter, we return a hidden state for each token.\n        # setting up the token classification head \n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n        # initialize the weights of the model\n        self.init_weights()\n\n    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, **kwargs)\n        sequence_output = self.dropout(outputs[0])\n        logits = self.classifier(sequence_output)\n        # calculate loss \n        loss = None\n        if labels is not None:\n            loss_fs = nn.CrossEntropyLoss()\n            loss = loss_fs(logits.view(-1, self.num_labels), labels.view(-1)) # CrossEntropyLoss() function expects 2D inputs (for that reason we use the view method)\n \n        return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions = outputs.attentions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:02.733857Z","iopub.execute_input":"2025-01-02T22:33:02.734079Z","iopub.status.idle":"2025-01-02T22:33:02.745937Z","shell.execute_reply.started":"2025-01-02T22:33:02.734053Z","shell.execute_reply":"2025-01-02T22:33:02.745163Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\ntag2index = {tag: idx for idx, tag in enumerate(tags.names)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:02.746705Z","iopub.execute_input":"2025-01-02T22:33:02.746926Z","iopub.status.idle":"2025-01-02T22:33:02.762137Z","shell.execute_reply.started":"2025-01-02T22:33:02.746908Z","shell.execute_reply":"2025-01-02T22:33:02.761454Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"index2tag","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:02.763043Z","iopub.execute_input":"2025-01-02T22:33:02.763322Z","iopub.status.idle":"2025-01-02T22:33:02.778100Z","shell.execute_reply.started":"2025-01-02T22:33:02.763294Z","shell.execute_reply":"2025-01-02T22:33:02.777336Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{0: 'O',\n 1: 'B-PER',\n 2: 'I-PER',\n 3: 'B-ORG',\n 4: 'I-ORG',\n 5: 'B-LOC',\n 6: 'I-LOC'}"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"from transformers import AutoConfig \n\nxlmr_config = AutoConfig.from_pretrained(xlmr_model_name, num_labels=tags.num_classes, id2label=index2tag, label2id = tag2index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:02.778877Z","iopub.execute_input":"2025-01-02T22:33:02.779138Z","iopub.status.idle":"2025-01-02T22:33:02.838079Z","shell.execute_reply.started":"2025-01-02T22:33:02.779118Z","shell.execute_reply":"2025-01-02T22:33:02.837316Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nxlmr_model = XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name, config=xlmr_config).to(device) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:02.842017Z","iopub.execute_input":"2025-01-02T22:33:02.842244Z","iopub.status.idle":"2025-01-02T22:33:17.088122Z","shell.execute_reply.started":"2025-01-02T22:33:02.842226Z","shell.execute_reply":"2025-01-02T22:33:17.087132Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e19dd9326a442b7800dd9469d5c61ab"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\npd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.090096Z","iopub.execute_input":"2025-01-02T22:33:17.090356Z","iopub.status.idle":"2025-01-02T22:33:17.102210Z","shell.execute_reply.started":"2025-01-02T22:33:17.090316Z","shell.execute_reply":"2025-01-02T22:33:17.101440Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"             0      1      2      3      4  5     6      7   8     9\nTokens     <s>  ▁Jack  ▁Spar    row  ▁love  s  ▁New  ▁York   !  </s>\nInput IDs    0  21763  37456  15555   5161  7  2356   5753  38     2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jack</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁love</td>\n      <td>s</td>\n      <td>▁New</td>\n      <td>▁York</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Input IDs</th>\n      <td>0</td>\n      <td>21763</td>\n      <td>37456</td>\n      <td>15555</td>\n      <td>5161</td>\n      <td>7</td>\n      <td>2356</td>\n      <td>5753</td>\n      <td>38</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"outputs = xlmr_model(input_ids.to(device)).logits\npredictions = torch.argmax(outputs, axis=-1)\nprint(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\nprint(f\"Shape of outputs: {outputs.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.103090Z","iopub.execute_input":"2025-01-02T22:33:17.103337Z","iopub.status.idle":"2025-01-02T22:33:17.609419Z","shell.execute_reply.started":"2025-01-02T22:33:17.103315Z","shell.execute_reply":"2025-01-02T22:33:17.608677Z"}},"outputs":[{"name":"stdout","text":"Number of tokens in sequence: 10\nShape of outputs: torch.Size([1, 10, 7])\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.610099Z","iopub.execute_input":"2025-01-02T22:33:17.610303Z","iopub.status.idle":"2025-01-02T22:33:17.617284Z","shell.execute_reply.started":"2025-01-02T22:33:17.610286Z","shell.execute_reply":"2025-01-02T22:33:17.616654Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"tensor([[4, 2, 2, 4, 4, 4, 4, 2, 4, 4]], device='cuda:0')"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"preds = [index2tag[p] for p in predictions[0].cpu().numpy()]\npd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.617948Z","iopub.execute_input":"2025-01-02T22:33:17.618172Z","iopub.status.idle":"2025-01-02T22:33:17.635869Z","shell.execute_reply.started":"2025-01-02T22:33:17.618153Z","shell.execute_reply":"2025-01-02T22:33:17.635184Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"            0      1      2      3      4      5      6      7      8      9\nTokens    <s>  ▁Jack  ▁Spar    row  ▁love      s   ▁New  ▁York      !   </s>\nTags    I-ORG  I-PER  I-PER  I-ORG  I-ORG  I-ORG  I-ORG  I-PER  I-ORG  I-ORG","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jack</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁love</td>\n      <td>s</td>\n      <td>▁New</td>\n      <td>▁York</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>I-ORG</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-PER</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"def tag_text(text, model, tokenizer):\n    tokens = tokenizer(text).tokens() \n    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n    outputs = model(input_ids)[0]\n    predictions = torch.argmax(outputs, dim=-1)\n    preds = preds = [index2tag[p] for p in predictions[0].cpu().numpy()]\n    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.636658Z","iopub.execute_input":"2025-01-02T22:33:17.636937Z","iopub.status.idle":"2025-01-02T22:33:17.649489Z","shell.execute_reply.started":"2025-01-02T22:33:17.636916Z","shell.execute_reply":"2025-01-02T22:33:17.648790Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"tag_text(text, xlmr_model, xlmr_tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.650327Z","iopub.execute_input":"2025-01-02T22:33:17.650604Z","iopub.status.idle":"2025-01-02T22:33:17.687409Z","shell.execute_reply.started":"2025-01-02T22:33:17.650534Z","shell.execute_reply":"2025-01-02T22:33:17.686645Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"            0      1      2      3      4      5      6      7      8      9\nTokens    <s>  ▁Jack  ▁Spar    row  ▁love      s   ▁New  ▁York      !   </s>\nTags    I-ORG  I-PER  I-PER  I-ORG  I-ORG  I-ORG  I-ORG  I-PER  I-ORG  I-ORG","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jack</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁love</td>\n      <td>s</td>\n      <td>▁New</td>\n      <td>▁York</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>I-ORG</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-PER</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"### Tokenizing Texts for NER (Dataset Preparation)","metadata":{}},{"cell_type":"code","source":"words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]\nwords, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.688194Z","iopub.execute_input":"2025-01-02T22:33:17.688466Z","iopub.status.idle":"2025-01-02T22:33:17.693486Z","shell.execute_reply.started":"2025-01-02T22:33:17.688437Z","shell.execute_reply":"2025-01-02T22:33:17.692723Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"(['2.000',\n  'Einwohnern',\n  'an',\n  'der',\n  'Danziger',\n  'Bucht',\n  'in',\n  'der',\n  'polnischen',\n  'Woiwodschaft',\n  'Pommern',\n  '.'],\n [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0])"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.694181Z","iopub.execute_input":"2025-01-02T22:33:17.694470Z","iopub.status.idle":"2025-01-02T22:33:17.706946Z","shell.execute_reply.started":"2025-01-02T22:33:17.694443Z","shell.execute_reply":"2025-01-02T22:33:17.706281Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"tokenized_input = xlmr_tokenizer(words, is_split_into_words = True) # the 2nd parameter is used to indicate the that input is already splitted into words (not full sentence) \ntokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\npd.DataFrame([tokens], index=[\"Tokens\"]) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.707692Z","iopub.execute_input":"2025-01-02T22:33:17.707942Z","iopub.status.idle":"2025-01-02T22:33:17.734020Z","shell.execute_reply.started":"2025-01-02T22:33:17.707913Z","shell.execute_reply":"2025-01-02T22:33:17.733359Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"         0       1           2  3    4     5     6   7    8      9   ...   15  \\\nTokens  <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...  ▁Wo   \n\n       16   17      18   19    20 21 22 23    24  \nTokens  i  wod  schaft  ▁Po  mmer  n  ▁  .  </s>  \n\n[1 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 25 columns</p>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"We need a way to mask the subword representations after the first subword.","metadata":{}},{"cell_type":"code","source":"print(tokenized_input.word_ids()) # this function returns the ids of the words (this will us mask the subsequent subwords, thus improving the loss calculation) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.734765Z","iopub.execute_input":"2025-01-02T22:33:17.734952Z","iopub.status.idle":"2025-01-02T22:33:17.738803Z","shell.execute_reply.started":"2025-01-02T22:33:17.734937Z","shell.execute_reply":"2025-01-02T22:33:17.737908Z"}},"outputs":[{"name":"stdout","text":"[None, 0, 1, 1, 2, 3, 4, 4, 4, 5, 5, 6, 7, 8, 8, 9, 9, 9, 9, 10, 10, 10, 11, 11, None]\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"word_ids = tokenized_input.word_ids()\npd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"Word IDs\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.739518Z","iopub.execute_input":"2025-01-02T22:33:17.739773Z","iopub.status.idle":"2025-01-02T22:33:17.763749Z","shell.execute_reply.started":"2025-01-02T22:33:17.739754Z","shell.execute_reply":"2025-01-02T22:33:17.763046Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"            0       1           2  3    4     5     6   7    8      9   ...  \\\nTokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...   \nWord IDs  None       0           1  1    2     3     4   4    4      5  ...   \n\n           15 16   17      18   19    20  21  22  23    24  \nTokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \nWord IDs    9  9    9       9   10    10  10  11  11  None  \n\n[2 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Word IDs</th>\n      <td>None</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>11</td>\n      <td>11</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 25 columns</p>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"previous_word_idx = None\nlabel_ids = []\n\nfor word_idx in word_ids:\n    if word_idx is None or word_idx == previous_word_idx:\n        label_ids.append(-100) # mark special tokens and subsequent subwords as -100 \n    elif word_idx != previous_word_idx: \n        label_ids.append(labels[word_idx])\n    previous_word_idx = word_idx\n\nlabels_tags = [index2tag[idx] if idx != -100 else \"IGN\" for idx in label_ids] # insert \"IGN\" tag for special tokens and subsequent subwords\nindex = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n\npd.DataFrame([tokens, word_ids, label_ids, labels_tags], index=index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.764375Z","iopub.execute_input":"2025-01-02T22:33:17.764623Z","iopub.status.idle":"2025-01-02T22:33:17.788205Z","shell.execute_reply.started":"2025-01-02T22:33:17.764598Z","shell.execute_reply":"2025-01-02T22:33:17.787576Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"             0       1           2     3    4     5      6     7     8   \\\nTokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger   \nWord IDs   None       0           1     1    2     3      4     4     4   \nLabel IDs  -100       0           0  -100    0     0      5  -100  -100   \nLabels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n\n              9   ...     15    16    17      18     19    20    21  22    23  \\\nTokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .   \nWord IDs       5  ...      9     9     9       9     10    10    10  11    11   \nLabel IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \nLabels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n\n             24  \nTokens     </s>  \nWord IDs   None  \nLabel IDs  -100  \nLabels      IGN  \n\n[4 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Word IDs</th>\n      <td>None</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>11</td>\n      <td>11</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>Label IDs</th>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>6</td>\n      <td>...</td>\n      <td>5</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>6</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>Labels</th>\n      <td>IGN</td>\n      <td>O</td>\n      <td>O</td>\n      <td>IGN</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>...</td>\n      <td>B-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>O</td>\n      <td>IGN</td>\n      <td>IGN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 25 columns</p>\n</div>"},"metadata":{}}],"execution_count":35},{"cell_type":"markdown","source":"> Why did we choose –100 as the ID to mask subword representations? The reason is that in PyTorch the cross-entropy loss class\n `torch.nn.CrossEntropyLoss` has an attribute called `ignore_index` whose value is –100. This index is ignored during training,\n so we can use it to ignore the tokens associated with consecutive subwords.","metadata":{}},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n    labels = []\n    for idx, label in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n        previous_word_idx = None\n        labels_ids = list()\n        for word_idx in word_ids:\n            if word_idx is None or word_idx == previous_word_idx:\n                labels_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                labels_ids.append(label[word_idx])\n            previous_word_idx = word_idx\n        labels.append(labels_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.788998Z","iopub.execute_input":"2025-01-02T22:33:17.789249Z","iopub.status.idle":"2025-01-02T22:33:17.804540Z","shell.execute_reply.started":"2025-01-02T22:33:17.789218Z","shell.execute_reply":"2025-01-02T22:33:17.803655Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"def encode_panx_dataset(corpus):\n    return corpus.map(tokenize_and_align_labels, batched=True, remove_columns=[\"langs\", \"ner_tags\", \"tokens\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.805425Z","iopub.execute_input":"2025-01-02T22:33:17.805743Z","iopub.status.idle":"2025-01-02T22:33:17.817587Z","shell.execute_reply.started":"2025-01-02T22:33:17.805694Z","shell.execute_reply":"2025-01-02T22:33:17.816860Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])\npanx_fr_encoded = encode_panx_dataset(panx_ch[\"fr\"])\npanx_it_encoded = encode_panx_dataset(panx_ch[\"it\"])\npanx_en_encoded = encode_panx_dataset(panx_ch[\"en\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:17.818367Z","iopub.execute_input":"2025-01-02T22:33:17.818652Z","iopub.status.idle":"2025-01-02T22:33:21.328068Z","shell.execute_reply.started":"2025-01-02T22:33:17.818619Z","shell.execute_reply":"2025-01-02T22:33:21.327162Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12580 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"623dca962e3843549403effb35ffc148"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6290 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ee7a3c0866e4aa6bacd71d3f89ee9b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6290 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2a4a1e8f48f418585655c9e1f7907be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4580 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c5462f6fd754d64a0aaf206c41d7248"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2290 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93144afd40da4ad0b6f09b5af78e604e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2290 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"664f33362af04992878635afe436a4c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1680 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6c2d1422205431488cc9c7b121f6fe3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/840 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d124b7d832d340b1a33c1ab893e65ec0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/840 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d9d0ee946b24da0a73d0adfb249c4e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1180 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f0bc5a4f0dc499aa1b00ba455d3e92a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/590 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"527e83e9858f41dba3c4a0a1db46bb12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/590 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82de60201ea2457a8dc1678b5e3f8088"}},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"panx_de_encoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:21.328781Z","iopub.execute_input":"2025-01-02T22:33:21.328992Z","iopub.status.idle":"2025-01-02T22:33:21.333884Z","shell.execute_reply.started":"2025-01-02T22:33:21.328964Z","shell.execute_reply":"2025-01-02T22:33:21.332974Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 12580\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 6290\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 6290\n    })\n})"},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"### Performance Measures","metadata":{}},{"cell_type":"code","source":"def align_predictions(predictions, label_ids):\n    preds = np.argmax(predictions, axis=-1)\n    batch_size, seq_length = preds.shape\n    labels_list, preds_list = [], []\n\n    for batch_idx in range(batch_size):\n        example_labels, example_preds = [], []\n        for seq_idx in range(seq_length):\n            # ignore label IDs = -100 (special tokens (start, end, padding) + subsequent subwords)\n            if label_ids[batch_idx, seq_idx] != -100:\n                example_labels.append(index2tag[label_ids[batch_idx, seq_idx]])\n                example_preds.append(index2tag[preds[batch_idx, seq_idx]])\n        labels_list.append(example_labels)\n        preds_list.append(example_preds)\n        \n    return preds_list, labels_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:21.334822Z","iopub.execute_input":"2025-01-02T22:33:21.335100Z","iopub.status.idle":"2025-01-02T22:33:21.363396Z","shell.execute_reply.started":"2025-01-02T22:33:21.335072Z","shell.execute_reply":"2025-01-02T22:33:21.362730Z"}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"##  Monolingual Fine-Tuning XLM-RoBERTa","metadata":{}},{"cell_type":"markdown","source":"### Fine-tune on German ONLY (Evaluate on German As Well)","metadata":{}},{"cell_type":"code","source":"num_epochs = 3\nbatch_size = 16\nlogging_steps = len(panx_de_encoded[\"train\"]) // batch_size\nmodel_name = f\"{xlmr_model_name}-finetuned-panx-de\"\ntraining_args = TrainingArguments(output_dir = model_name, log_level=\"error\", \n                                 num_train_epochs=num_epochs,\n                                 per_device_train_batch_size=batch_size, \n                                 per_device_eval_batch_size=batch_size,\n                                 evaluation_strategy=\"epoch\",\n                                      save_steps=1e6, weight_decay=0.01, disable_tqdm=False,\n                                 logging_steps=logging_steps, push_to_hub=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:21.364183Z","iopub.execute_input":"2025-01-02T22:33:21.364473Z","iopub.status.idle":"2025-01-02T22:33:21.408999Z","shell.execute_reply.started":"2025-01-02T22:33:21.364445Z","shell.execute_reply":"2025-01-02T22:33:21.408365Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"access_token = \"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\"\nfrom huggingface_hub import login\nlogin(token=access_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:21.409686Z","iopub.execute_input":"2025-01-02T22:33:21.409957Z","iopub.status.idle":"2025-01-02T22:33:21.452493Z","shell.execute_reply.started":"2025-01-02T22:33:21.409936Z","shell.execute_reply":"2025-01-02T22:33:21.451709Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"import wandb\ntoken=\"f236cefcf4b4d7ae5f7fb8ba773bd6cf5f5eff37\"\nwandb.login(key=token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:21.453272Z","iopub.execute_input":"2025-01-02T22:33:21.453483Z","iopub.status.idle":"2025-01-02T22:33:28.751291Z","shell.execute_reply.started":"2025-01-02T22:33:21.453453Z","shell.execute_reply":"2025-01-02T22:33:28.750646Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshawki11\u001b[0m (\u001b[33mshawki11-cairo-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    y_pred, y_true = align_predictions(eval_pred.predictions, eval_pred.label_ids)\n    return {\"f1\": f1_score(y_true, y_pred)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:28.752091Z","iopub.execute_input":"2025-01-02T22:33:28.752683Z","iopub.status.idle":"2025-01-02T22:33:28.756411Z","shell.execute_reply.started":"2025-01-02T22:33:28.752659Z","shell.execute_reply":"2025-01-02T22:33:28.755643Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(xlmr_tokenizer) # for padding the labels of each sequence in the batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:28.757191Z","iopub.execute_input":"2025-01-02T22:33:28.757410Z","iopub.status.idle":"2025-01-02T22:33:28.772709Z","shell.execute_reply.started":"2025-01-02T22:33:28.757379Z","shell.execute_reply":"2025-01-02T22:33:28.771860Z"}},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":">  One important detail here is that the label sequences are padded with the value –100, which, as we’ve seen, is ignored by PyTorch loss functions","metadata":{}},{"cell_type":"code","source":"def model_init():\n    return XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name, config=xlmr_config).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:28.773619Z","iopub.execute_input":"2025-01-02T22:33:28.773839Z","iopub.status.idle":"2025-01-02T22:33:28.787486Z","shell.execute_reply.started":"2025-01-02T22:33:28.773820Z","shell.execute_reply":"2025-01-02T22:33:28.786827Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"trainer = Trainer(model_init=model_init, args=training_args, data_collator=data_collator, compute_metrics=compute_metrics,\n                 train_dataset=panx_de_encoded[\"train\"], eval_dataset=panx_de_encoded[\"validation\"],\n                 tokenizer=xlmr_tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:28.788322Z","iopub.execute_input":"2025-01-02T22:33:28.788580Z","iopub.status.idle":"2025-01-02T22:33:29.467399Z","shell.execute_reply.started":"2025-01-02T22:33:28.788533Z","shell.execute_reply":"2025-01-02T22:33:29.466501Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"trainer.train(), trainer.push_to_hub(commit_message=\"Training completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:33:29.468254Z","iopub.execute_input":"2025-01-02T22:33:29.468520Z","iopub.status.idle":"2025-01-02T22:39:11.463632Z","shell.execute_reply.started":"2025-01-02T22:33:29.468487Z","shell.execute_reply":"2025-01-02T22:39:11.462882Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250102_223331-5ruq9f6y</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shawki11-cairo-university/huggingface/runs/5ruq9f6y' target=\"_blank\">xlm-roberta-base-finetuned-panx-de</a></strong> to <a href='https://wandb.ai/shawki11-cairo-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shawki11-cairo-university/huggingface' target=\"_blank\">https://wandb.ai/shawki11-cairo-university/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shawki11-cairo-university/huggingface/runs/5ruq9f6y' target=\"_blank\">https://wandb.ai/shawki11-cairo-university/huggingface/runs/5ruq9f6y</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2361' max='2361' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2361/2361 05:24, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.256100</td>\n      <td>0.155045</td>\n      <td>0.821244</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.126700</td>\n      <td>0.144529</td>\n      <td>0.853413</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.075600</td>\n      <td>0.146951</td>\n      <td>0.863046</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735857211.f12717e130b1.40.0:   0%|          | 0.00/7.22k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22777f1adc96430cace689d2ec8e83f9"}},"metadata":{}},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(TrainOutput(global_step=2361, training_loss=0.15277006046997194, metrics={'train_runtime': 331.4787, 'train_samples_per_second': 113.853, 'train_steps_per_second': 7.123, 'total_flos': 792244708985400.0, 'train_loss': 0.15277006046997194, 'epoch': 3.0}),\n CommitInfo(commit_url='https://huggingface.co/Shawki11/xlm-roberta-base-finetuned-panx-de/commit/55e2d8109b287f32db984b36dfc0b17e633cbcdd', commit_message='Training completed!', commit_description='', oid='55e2d8109b287f32db984b36dfc0b17e633cbcdd', pr_url=None, pr_revision=None, pr_num=None))"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"text_de = \"Jeff Dean ist ein Informatiker bei Google in Kalifornien\"\ntag_text(text_de, trainer.model, xlmr_tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:39:11.464430Z","iopub.execute_input":"2025-01-02T22:39:11.464679Z","iopub.status.idle":"2025-01-02T22:39:11.491309Z","shell.execute_reply.started":"2025-01-02T22:39:11.464654Z","shell.execute_reply":"2025-01-02T22:39:11.490720Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"         0      1      2      3     4     5           6    7     8        9   \\\nTokens  <s>  ▁Jeff    ▁De     an  ▁ist  ▁ein  ▁Informati  ker  ▁bei  ▁Google   \nTags      O  B-PER  I-PER  I-PER     O     O           O    O     O    B-ORG   \n\n         10          11     12    13  \nTokens  ▁in  ▁Kaliforni     en  </s>  \nTags      O       B-LOC  I-LOC     O  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jeff</td>\n      <td>▁De</td>\n      <td>an</td>\n      <td>▁ist</td>\n      <td>▁ein</td>\n      <td>▁Informati</td>\n      <td>ker</td>\n      <td>▁bei</td>\n      <td>▁Google</td>\n      <td>▁in</td>\n      <td>▁Kaliforni</td>\n      <td>en</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>O</td>\n      <td>B-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-ORG</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"markdown","source":"### Error Analysis ","metadata":{}},{"cell_type":"code","source":"tags.names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:39:11.492002Z","iopub.execute_input":"2025-01-02T22:39:11.492213Z","iopub.status.idle":"2025-01-02T22:39:12.803546Z","shell.execute_reply.started":"2025-01-02T22:39:11.492194Z","shell.execute_reply":"2025-01-02T22:39:12.802682Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"def forward_pass_with_loss(batch):\n    # convert the batch from being dict of lists to lists of dicts (for data collator)\n    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n    # padding inputs and labels to have the same dimension\n    batch = data_collator(features) \n    input_ids = batch[\"input_ids\"].to(device)\n    attention_mask = batch[\"attention_mask\"].to(device)\n    labels = batch[\"labels\"].to(device)\n\n    with torch.no_grad():\n        # pass the data through the model \n        outputs = trainer.model(input_ids, attention_mask)\n        # logit.size: [batch_size, sequence_length, classes] \n        # Predict class with largest logit value on classes axis\n        predicted_labels = torch.argmax(outputs.logits, axis=-1).cpu().numpy()\n\n    loss = cross_entropy(outputs.logits.view(-1, 7), labels.view(-1), reduction = \"none\") # return the loss for each token per each individual example\n    loss = loss.view(len(input_ids), -1).cpu().numpy() # per (examples, loss per each token)\n\n    return {\"loss\": loss, \"predicted_label\": predicted_labels}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:39:12.804506Z","iopub.execute_input":"2025-01-02T22:39:12.804844Z","iopub.status.idle":"2025-01-02T22:39:14.160597Z","shell.execute_reply.started":"2025-01-02T22:39:12.804808Z","shell.execute_reply":"2025-01-02T22:39:14.159485Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"valid_set = panx_de_encoded[\"validation\"]\nvalid_set","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:39:14.161547Z","iopub.execute_input":"2025-01-02T22:39:14.161861Z","iopub.status.idle":"2025-01-02T22:39:14.833956Z","shell.execute_reply.started":"2025-01-02T22:39:14.161831Z","shell.execute_reply":"2025-01-02T22:39:14.833170Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 6290\n})"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"valid_set = valid_set.map(forward_pass_with_loss, batched=True, batch_size=32)\nvalid_set","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:39:14.834683Z","iopub.execute_input":"2025-01-02T22:39:14.834886Z","iopub.status.idle":"2025-01-02T22:39:29.948685Z","shell.execute_reply.started":"2025-01-02T22:39:14.834869Z","shell.execute_reply":"2025-01-02T22:39:29.947909Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6290 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1890fd92b694c3e86c5da98295acc3b"}},"metadata":{}},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'labels', 'loss', 'predicted_label'],\n    num_rows: 6290\n})"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"df = valid_set.to_pandas()\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:39:29.949431Z","iopub.execute_input":"2025-01-02T22:39:29.949752Z","iopub.status.idle":"2025-01-02T22:39:29.983464Z","shell.execute_reply.started":"2025-01-02T22:39:29.949719Z","shell.execute_reply":"2025-01-02T22:39:29.982705Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"                                           input_ids  \\\n0                 [0, 10699, 11, 15, 16104, 1388, 2]   \n1  [0, 56530, 25216, 30121, 152385, 19229, 83982,...   \n2  [0, 159093, 165, 38506, 122, 153080, 29088, 57...   \n3     [0, 16459, 242, 5106, 6, 198715, 5106, 242, 2]   \n4  [0, 11022, 2315, 7418, 1079, 8186, 57242, 97, ...   \n\n                                      attention_mask  \\\n0                              [1, 1, 1, 1, 1, 1, 1]   \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n2         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n3                        [1, 1, 1, 1, 1, 1, 1, 1, 1]   \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n\n                                              labels  \\\n0                     [-100, 3, -100, 4, 4, 4, -100]   \n1  [-100, 0, -100, -100, -100, -100, 3, -100, -10...   \n2  [-100, 0, 0, 0, 0, 3, -100, -100, 0, -100, 0, ...   \n3               [-100, 0, 0, 0, 5, -100, 0, 0, -100]   \n4  [-100, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 3, ...   \n\n                                                loss  \\\n0  [0.0, 0.010196972, 0.0, 0.019250939, 0.0139847...   \n1  [0.0, 0.00018451895, 0.0, 0.0, 0.0, 0.0, 0.467...   \n2  [0.0, 0.00016830936, 0.00010144196, 0.00014399...   \n3  [0.0, 0.00014947727, 0.00014304092, 0.00014256...   \n4  [0.0, 0.000102157144, 9.285972e-05, 0.00011753...   \n\n                                     predicted_label  \n0  [4, 3, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, ...  \n1  [4, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, ...  \n2  [0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [5, 0, 0, 0, 5, 5, 0, 0, 0, 5, 5, 5, 5, 5, 5, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n      <th>labels</th>\n      <th>loss</th>\n      <th>predicted_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0, 10699, 11, 15, 16104, 1388, 2]</td>\n      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n      <td>[-100, 3, -100, 4, 4, 4, -100]</td>\n      <td>[0.0, 0.010196972, 0.0, 0.019250939, 0.0139847...</td>\n      <td>[4, 3, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0, 56530, 25216, 30121, 152385, 19229, 83982,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[-100, 0, -100, -100, -100, -100, 3, -100, -10...</td>\n      <td>[0.0, 0.00018451895, 0.0, 0.0, 0.0, 0.0, 0.467...</td>\n      <td>[4, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 159093, 165, 38506, 122, 153080, 29088, 57...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n      <td>[-100, 0, 0, 0, 0, 3, -100, -100, 0, -100, 0, ...</td>\n      <td>[0.0, 0.00016830936, 0.00010144196, 0.00014399...</td>\n      <td>[0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0, 16459, 242, 5106, 6, 198715, 5106, 242, 2]</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n      <td>[-100, 0, 0, 0, 5, -100, 0, 0, -100]</td>\n      <td>[0.0, 0.00014947727, 0.00014304092, 0.00014256...</td>\n      <td>[5, 0, 0, 0, 5, 5, 0, 0, 0, 5, 5, 5, 5, 5, 5, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[0, 11022, 2315, 7418, 1079, 8186, 57242, 97, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[-100, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 3, ...</td>\n      <td>[0.0, 0.000102157144, 9.285972e-05, 0.00011753...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":54},{"cell_type":"markdown","source":"The tokens and the labels are still encoded with their IDs, so let’s map the tokens and labels back to strings to\n make it easier to read the results. For the padding tokens with label –100 we assign a special label, IGN, so we can\n filter them later. We also get rid of all the padding in the loss and predicted_label fields by truncating\n them to the length of the inputs.","metadata":{}},{"cell_type":"code","source":"index2tag[-100] = \"IGN\"\ndf[\"input_tokens\"] = df[\"input_ids\"].apply(lambda x: xlmr_tokenizer.convert_ids_to_tokens(x))\ndf[\"predicted_label\"] = df[\"predicted_label\"].apply(lambda x: [index2tag[i] for i in x])\ndf[\"labels\"] = df[\"labels\"].apply(lambda x: [index2tag[i] for i in x])\ndf[\"loss\"] = df.apply(lambda x: x[\"loss\"][:len(x[\"input_ids\"])], axis=1) # across columns\ndf[\"predicted_label\"] = df.apply(lambda x: x[\"predicted_label\"][:len(x[\"input_ids\"])], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:39:29.984342Z","iopub.execute_input":"2025-01-02T22:39:29.984652Z","iopub.status.idle":"2025-01-02T22:39:30.245182Z","shell.execute_reply.started":"2025-01-02T22:39:29.984622Z","shell.execute_reply":"2025-01-02T22:39:30.244248Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"df.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:39:30.246065Z","iopub.execute_input":"2025-01-02T22:39:30.246342Z","iopub.status.idle":"2025-01-02T22:39:30.257876Z","shell.execute_reply.started":"2025-01-02T22:39:30.246313Z","shell.execute_reply":"2025-01-02T22:39:30.257023Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"                            input_ids         attention_mask  \\\n0  [0, 10699, 11, 15, 16104, 1388, 2]  [1, 1, 1, 1, 1, 1, 1]   \n\n                                        labels  \\\n0  [IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]   \n\n                                                loss  \\\n0  [0.0, 0.010196972, 0.0, 0.019250939, 0.0139847...   \n\n                                 predicted_label  \\\n0  [I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O]   \n\n                                 input_tokens  \n0  [<s>, ▁Ham, a, ▁(, ▁Unternehmen, ▁), </s>]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n      <th>labels</th>\n      <th>loss</th>\n      <th>predicted_label</th>\n      <th>input_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0, 10699, 11, 15, 16104, 1388, 2]</td>\n      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n      <td>[IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]</td>\n      <td>[0.0, 0.010196972, 0.0, 0.019250939, 0.0139847...</td>\n      <td>[I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O]</td>\n      <td>[&lt;s&gt;, ▁Ham, a, ▁(, ▁Unternehmen, ▁), &lt;/s&gt;]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"df_tokens = df.apply(pd.Series.explode) # this is only applicable when all the lists of each entry in the df has the same length \ndf_tokens = df_tokens.query(\"labels != 'IGN'\") # drop the IGN tokens (as their loss is already zero)\ndf_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\ndf_tokens.head(7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:39:30.258585Z","iopub.execute_input":"2025-01-02T22:39:30.258820Z","iopub.status.idle":"2025-01-02T22:39:30.353315Z","shell.execute_reply.started":"2025-01-02T22:39:30.258802Z","shell.execute_reply":"2025-01-02T22:39:30.352614Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"  input_ids attention_mask labels  loss predicted_label  input_tokens\n0     10699              1  B-ORG  0.01           B-ORG          ▁Ham\n0        15              1  I-ORG  0.02           I-ORG            ▁(\n0     16104              1  I-ORG  0.01           I-ORG  ▁Unternehmen\n0      1388              1  I-ORG  0.02           I-ORG            ▁)\n1     56530              1      O  0.00               O           ▁WE\n1     83982              1  B-ORG  0.47           B-ORG          ▁Luz\n1        10              1  I-ORG  0.33           I-ORG            ▁a","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n      <th>labels</th>\n      <th>loss</th>\n      <th>predicted_label</th>\n      <th>input_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10699</td>\n      <td>1</td>\n      <td>B-ORG</td>\n      <td>0.01</td>\n      <td>B-ORG</td>\n      <td>▁Ham</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>15</td>\n      <td>1</td>\n      <td>I-ORG</td>\n      <td>0.02</td>\n      <td>I-ORG</td>\n      <td>▁(</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>16104</td>\n      <td>1</td>\n      <td>I-ORG</td>\n      <td>0.01</td>\n      <td>I-ORG</td>\n      <td>▁Unternehmen</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1388</td>\n      <td>1</td>\n      <td>I-ORG</td>\n      <td>0.02</td>\n      <td>I-ORG</td>\n      <td>▁)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56530</td>\n      <td>1</td>\n      <td>O</td>\n      <td>0.00</td>\n      <td>O</td>\n      <td>▁WE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>83982</td>\n      <td>1</td>\n      <td>B-ORG</td>\n      <td>0.47</td>\n      <td>B-ORG</td>\n      <td>▁Luz</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10</td>\n      <td>1</td>\n      <td>I-ORG</td>\n      <td>0.33</td>\n      <td>I-ORG</td>\n      <td>▁a</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":57},{"cell_type":"markdown","source":"With the data in this shape, we can now group it by the input tokens and aggregate the losses for each token with\nthe count, mean, and sum. Finally, we sort the aggregated data by the sum of the losses and see which tokens have\naccumulated the most loss in the validation set.","metadata":{}},{"cell_type":"code","source":"df_tokens.groupby(\"input_tokens\")[[\"loss\"]].agg([\"count\", \"mean\", \"sum\"]).droplevel(level=0, axis=1).sort_values(by=\"sum\", ascending=False).reset_index().round(2).head(10).T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:39:30.354147Z","iopub.execute_input":"2025-01-02T22:39:30.354410Z","iopub.status.idle":"2025-01-02T22:39:30.393535Z","shell.execute_reply.started":"2025-01-02T22:39:30.354388Z","shell.execute_reply":"2025-01-02T22:39:30.392778Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"                   0       1       2       3       4      5     6      7  \\\ninput_tokens       ▁    ▁der    ▁von     ▁in      ▁/     ▁)    ▁(   ▁und   \ncount           6066    1388     808     989     163    246   246   1171   \nmean            0.04    0.11    0.19    0.14    0.62   0.39  0.38   0.08   \nsum           236.43  158.04  151.04  142.65  101.81  94.75  93.6  91.61   \n\n                  8      9  \ninput_tokens    ▁''   ▁die  \ncount          2898    860  \nmean           0.03   0.06  \nsum           73.83  52.93  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>input_tokens</th>\n      <td>▁</td>\n      <td>▁der</td>\n      <td>▁von</td>\n      <td>▁in</td>\n      <td>▁/</td>\n      <td>▁)</td>\n      <td>▁(</td>\n      <td>▁und</td>\n      <td>▁''</td>\n      <td>▁die</td>\n    </tr>\n    <tr>\n      <th>count</th>\n      <td>6066</td>\n      <td>1388</td>\n      <td>808</td>\n      <td>989</td>\n      <td>163</td>\n      <td>246</td>\n      <td>246</td>\n      <td>1171</td>\n      <td>2898</td>\n      <td>860</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.04</td>\n      <td>0.11</td>\n      <td>0.19</td>\n      <td>0.14</td>\n      <td>0.62</td>\n      <td>0.39</td>\n      <td>0.38</td>\n      <td>0.08</td>\n      <td>0.03</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>sum</th>\n      <td>236.43</td>\n      <td>158.04</td>\n      <td>151.04</td>\n      <td>142.65</td>\n      <td>101.81</td>\n      <td>94.75</td>\n      <td>93.6</td>\n      <td>91.61</td>\n      <td>73.83</td>\n      <td>52.93</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":58},{"cell_type":"markdown","source":"We can observe several patterns in this list:\n - The whitespace token has the highest total loss, which is not surprising since it is also the most common\n token in the list. However, its mean loss is much lower than the other tokens in the list. This means that\n the model doesn’t struggle to classify it.\n - Words like “in”, “von”, “der”, and “und” appear relatively frequently. They often appear together with\n named entities and are sometimes part of them, which explains why the model might mix them up.\n - Parentheses, slashes, and capital letters at the beginning of words are rarer but have a relatively high\n average loss. We will investigate them further.","metadata":{}},{"cell_type":"code","source":" df_tokens.groupby(\"labels\")[[\"loss\"]].agg([\"count\", \"mean\", \"sum\"]).droplevel(level=0, axis=1).sort_values(by=\"mean\", ascending=False).reset_index().round(2).T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:39:30.394245Z","iopub.execute_input":"2025-01-02T22:39:30.394445Z","iopub.status.idle":"2025-01-02T22:39:30.412669Z","shell.execute_reply.started":"2025-01-02T22:39:30.394427Z","shell.execute_reply":"2025-01-02T22:39:30.412038Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"              0        1        2        3       4       5        6\nlabels    I-LOC    B-ORG    I-ORG    B-LOC   B-PER   I-PER        O\ncount      1462     2683     3820     3172    2893    4139    43648\nmean       0.75     0.61     0.55     0.36    0.26     0.2     0.03\nsum     1090.47  1646.98  2111.09  1155.92  762.84  825.53  1396.59","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>labels</th>\n      <td>I-LOC</td>\n      <td>B-ORG</td>\n      <td>I-ORG</td>\n      <td>B-LOC</td>\n      <td>B-PER</td>\n      <td>I-PER</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>count</th>\n      <td>1462</td>\n      <td>2683</td>\n      <td>3820</td>\n      <td>3172</td>\n      <td>2893</td>\n      <td>4139</td>\n      <td>43648</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.75</td>\n      <td>0.61</td>\n      <td>0.55</td>\n      <td>0.36</td>\n      <td>0.26</td>\n      <td>0.2</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>sum</th>\n      <td>1090.47</td>\n      <td>1646.98</td>\n      <td>2111.09</td>\n      <td>1155.92</td>\n      <td>762.84</td>\n      <td>825.53</td>\n      <td>1396.59</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"def plot_confusion_matrix(y_preds, y_true, labels):\n    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n    fig, ax = plt.subplots(figsize=(6,6))\n    disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels=labels)\n    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n    plt.title(\"Normalized confusion matrix\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:39:30.413414Z","iopub.execute_input":"2025-01-02T22:39:30.413674Z","iopub.status.idle":"2025-01-02T22:39:30.418413Z","shell.execute_reply.started":"2025-01-02T22:39:30.413649Z","shell.execute_reply":"2025-01-02T22:39:30.417720Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"plot_confusion_matrix(df_tokens[\"predicted_label\"], df_tokens[\"labels\"], tags.names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:04:04.281542Z","iopub.execute_input":"2025-01-02T23:04:04.281924Z","iopub.status.idle":"2025-01-02T23:04:04.788529Z","shell.execute_reply.started":"2025-01-02T23:04:04.281899Z","shell.execute_reply":"2025-01-02T23:04:04.787579Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"# define a generate for formating the inputs \ndef get_sample(df):\n    for _, row in df.iterrows():\n        labels, preds, tokens, losses = [], [], [], []\n        for i, mask in enumerate(row[\"attention_mask\"]):\n            if i not in {0, (len(row[\"attention_mask\"])-1)}: # exclude first and last indices\n                labels.append(row[\"labels\"][i])\n                preds.append(row[\"predicted_label\"][i])\n                tokens.append(row[\"input_tokens\"][i])\n                losses.append(f\"{row['loss'][i]:.2f}\")\n        df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\": labels, \"predictions\": preds, \"losses\": losses}).T\n\n        yield df_tmp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:31:21.761065Z","iopub.execute_input":"2025-01-02T23:31:21.761356Z","iopub.status.idle":"2025-01-02T23:31:21.767442Z","shell.execute_reply.started":"2025-01-02T23:31:21.761335Z","shell.execute_reply":"2025-01-02T23:31:21.766686Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:27:56.956125Z","iopub.execute_input":"2025-01-02T23:27:56.956420Z","iopub.status.idle":"2025-01-02T23:27:56.978959Z","shell.execute_reply.started":"2025-01-02T23:27:56.956398Z","shell.execute_reply":"2025-01-02T23:27:56.977885Z"}},"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"                                           input_ids  \\\n0                 [0, 10699, 11, 15, 16104, 1388, 2]   \n1  [0, 56530, 25216, 30121, 152385, 19229, 83982,...   \n2  [0, 159093, 165, 38506, 122, 153080, 29088, 57...   \n3     [0, 16459, 242, 5106, 6, 198715, 5106, 242, 2]   \n4  [0, 11022, 2315, 7418, 1079, 8186, 57242, 97, ...   \n\n                                      attention_mask  \\\n0                              [1, 1, 1, 1, 1, 1, 1]   \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n2         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n3                        [1, 1, 1, 1, 1, 1, 1, 1, 1]   \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n\n                                              labels  \\\n0        [IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]   \n1  [IGN, O, IGN, IGN, IGN, IGN, B-ORG, IGN, IGN, ...   \n2  [IGN, O, O, O, O, B-ORG, IGN, IGN, O, IGN, O, ...   \n3              [IGN, O, O, O, B-LOC, IGN, O, O, IGN]   \n4  [IGN, O, O, O, O, O, O, O, IGN, O, O, O, B-ORG...   \n\n                                                loss  \\\n0  [0.0, 0.010196972, 0.0, 0.019250939, 0.0139847...   \n1  [0.0, 0.00018451895, 0.0, 0.0, 0.0, 0.0, 0.467...   \n2  [0.0, 0.00016830936, 0.00010144196, 0.00014399...   \n3  [0.0, 0.00014947727, 0.00014304092, 0.00014256...   \n4  [0.0, 0.000102157144, 9.285972e-05, 0.00011753...   \n\n                                     predicted_label  \\\n0      [I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O]   \n1  [I-ORG, O, O, O, O, O, B-ORG, I-ORG, I-ORG, I-...   \n2     [O, O, O, O, O, B-ORG, O, O, O, O, O, O, O, O]   \n3            [B-LOC, O, O, O, B-LOC, B-LOC, O, O, O]   \n4  [O, O, O, O, O, O, O, O, O, O, O, O, B-ORG, I-...   \n\n                                        input_tokens  total_loss  \n0         [<s>, ▁Ham, a, ▁(, ▁Unternehmen, ▁), </s>]    0.058647  \n1  [<s>, ▁WE, ITE, RL, EIT, UNG, ▁Luz, ky, j, ▁a,...    1.263945  \n2  [<s>, ▁entdeckt, ▁und, ▁gehört, ▁der, ▁Spek, t...    0.174677  \n3    [<s>, ▁**, ▁', ▁'', ▁, Bretagne, ▁'', ▁', </s>]    0.019489  \n4  [<s>, ▁Nach, ▁einem, ▁Jahr, ▁bei, ▁diesem, ▁Ve...    0.009657  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n      <th>labels</th>\n      <th>loss</th>\n      <th>predicted_label</th>\n      <th>input_tokens</th>\n      <th>total_loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0, 10699, 11, 15, 16104, 1388, 2]</td>\n      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n      <td>[IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]</td>\n      <td>[0.0, 0.010196972, 0.0, 0.019250939, 0.0139847...</td>\n      <td>[I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O]</td>\n      <td>[&lt;s&gt;, ▁Ham, a, ▁(, ▁Unternehmen, ▁), &lt;/s&gt;]</td>\n      <td>0.058647</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0, 56530, 25216, 30121, 152385, 19229, 83982,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[IGN, O, IGN, IGN, IGN, IGN, B-ORG, IGN, IGN, ...</td>\n      <td>[0.0, 0.00018451895, 0.0, 0.0, 0.0, 0.0, 0.467...</td>\n      <td>[I-ORG, O, O, O, O, O, B-ORG, I-ORG, I-ORG, I-...</td>\n      <td>[&lt;s&gt;, ▁WE, ITE, RL, EIT, UNG, ▁Luz, ky, j, ▁a,...</td>\n      <td>1.263945</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 159093, 165, 38506, 122, 153080, 29088, 57...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n      <td>[IGN, O, O, O, O, B-ORG, IGN, IGN, O, IGN, O, ...</td>\n      <td>[0.0, 0.00016830936, 0.00010144196, 0.00014399...</td>\n      <td>[O, O, O, O, O, B-ORG, O, O, O, O, O, O, O, O]</td>\n      <td>[&lt;s&gt;, ▁entdeckt, ▁und, ▁gehört, ▁der, ▁Spek, t...</td>\n      <td>0.174677</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0, 16459, 242, 5106, 6, 198715, 5106, 242, 2]</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n      <td>[IGN, O, O, O, B-LOC, IGN, O, O, IGN]</td>\n      <td>[0.0, 0.00014947727, 0.00014304092, 0.00014256...</td>\n      <td>[B-LOC, O, O, O, B-LOC, B-LOC, O, O, O]</td>\n      <td>[&lt;s&gt;, ▁**, ▁', ▁'', ▁, Bretagne, ▁'', ▁', &lt;/s&gt;]</td>\n      <td>0.019489</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[0, 11022, 2315, 7418, 1079, 8186, 57242, 97, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[IGN, O, O, O, O, O, O, O, IGN, O, O, O, B-ORG...</td>\n      <td>[0.0, 0.000102157144, 9.285972e-05, 0.00011753...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-ORG, I-...</td>\n      <td>[&lt;s&gt;, ▁Nach, ▁einem, ▁Jahr, ▁bei, ▁diesem, ▁Ve...</td>\n      <td>0.009657</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":71},{"cell_type":"code","source":"df[\"total_loss\"] = df[\"loss\"].apply(sum) # total loss per sequence of tokens\ndf_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(3).reset_index()\n\nfor i,sample in enumerate(get_sample(df_tmp)): # this will return a generate \n    print(f\"With total loss of: {df_tmp['total_loss'][i]}\")\n    display(sample)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:31:22.786898Z","iopub.execute_input":"2025-01-02T23:31:22.787183Z","iopub.status.idle":"2025-01-02T23:31:22.862339Z","shell.execute_reply.started":"2025-01-02T23:31:22.787162Z","shell.execute_reply":"2025-01-02T23:31:22.861645Z"}},"outputs":[{"name":"stdout","text":"With total loss of: 87.08018306034501\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"               0     1      2      3     4     5      6      7      8      9   \\\ntokens         ▁'   ▁''     ▁Τ      Κ   ▁''    ▁'     ▁'    ▁''     ▁T    ▁''   \nlabels          O     O      O    IGN     O     O  B-LOC  I-LOC  I-LOC  I-LOC   \npredictions     O     O  B-ORG  I-ORG     O     O      O      O  B-ORG      O   \nlosses       0.00  0.00   5.61   0.00  0.00  0.00  11.40  10.62   9.66   6.50   \n\n                10    11     12     13    14     15     16    17  \ntokens          ▁'    ri    ▁''     ▁'     k    ▁''     ▁'   ala  \nlabels       I-LOC   IGN  I-LOC  I-LOC   IGN  I-LOC  I-LOC   IGN  \npredictions      O     O      O      O     O      O      O     O  \nlosses        7.13  0.00   7.74   9.45  0.00   9.16   9.81  0.00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tokens</th>\n      <td>▁'</td>\n      <td>▁''</td>\n      <td>▁Τ</td>\n      <td>Κ</td>\n      <td>▁''</td>\n      <td>▁'</td>\n      <td>▁'</td>\n      <td>▁''</td>\n      <td>▁T</td>\n      <td>▁''</td>\n      <td>▁'</td>\n      <td>ri</td>\n      <td>▁''</td>\n      <td>▁'</td>\n      <td>k</td>\n      <td>▁''</td>\n      <td>▁'</td>\n      <td>ala</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>IGN</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n    </tr>\n    <tr>\n      <th>predictions</th>\n      <td>O</td>\n      <td>O</td>\n      <td>B-ORG</td>\n      <td>I-ORG</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-ORG</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>losses</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>5.61</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>11.40</td>\n      <td>10.62</td>\n      <td>9.66</td>\n      <td>6.50</td>\n      <td>7.13</td>\n      <td>0.00</td>\n      <td>7.74</td>\n      <td>9.45</td>\n      <td>0.00</td>\n      <td>9.16</td>\n      <td>9.81</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"With total loss of: 83.36357350926846\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                0     1     2      3      4      5         6     7      8   \\\ntokens         ▁''     8     .  ▁Juli    ▁''     ▁:  ▁Protest  camp   ▁auf   \nlabels       B-ORG   IGN   IGN  I-ORG  I-ORG  I-ORG     I-ORG   IGN  I-ORG   \npredictions      O     O     O      O      O      O         O     O      O   \nlosses        8.54  0.00  0.00   7.70   9.00   9.88      7.94  0.00   8.20   \n\n                9         10     11          12     13      14     15     16  \ntokens        ▁dem  ▁Gelände   ▁der  ▁Republika      n  ischen   ▁Gar     de  \nlabels       I-ORG     I-ORG  I-ORG       I-ORG    IGN     IGN  I-ORG    IGN  \npredictions      O         O      O       B-ORG  I-ORG   I-ORG  I-ORG  I-ORG  \nlosses        9.55      8.13   8.06        6.36   0.00    0.00   0.01   0.00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tokens</th>\n      <td>▁''</td>\n      <td>8</td>\n      <td>.</td>\n      <td>▁Juli</td>\n      <td>▁''</td>\n      <td>▁:</td>\n      <td>▁Protest</td>\n      <td>camp</td>\n      <td>▁auf</td>\n      <td>▁dem</td>\n      <td>▁Gelände</td>\n      <td>▁der</td>\n      <td>▁Republika</td>\n      <td>n</td>\n      <td>ischen</td>\n      <td>▁Gar</td>\n      <td>de</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>B-ORG</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>IGN</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-ORG</td>\n      <td>IGN</td>\n    </tr>\n    <tr>\n      <th>predictions</th>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n    </tr>\n    <tr>\n      <th>losses</th>\n      <td>8.54</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>7.70</td>\n      <td>9.00</td>\n      <td>9.88</td>\n      <td>7.94</td>\n      <td>0.00</td>\n      <td>8.20</td>\n      <td>9.55</td>\n      <td>8.13</td>\n      <td>8.06</td>\n      <td>6.36</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"With total loss of: 70.94195938110352\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                  0         1       2            3         4      5        6   \\\ntokens       ▁United  ▁Nations  ▁Multi  dimensional  ▁Integra    ted  ▁Stabil   \nlabels         B-PER     I-PER   I-PER          IGN     I-PER    IGN    I-PER   \npredictions    B-ORG     I-ORG   I-ORG        I-ORG     I-ORG  I-ORG    I-ORG   \nlosses          6.86      6.55    6.49         0.00      6.39   0.00     6.21   \n\n                  7         8      9      10        11        12         13  \ntokens       ization  ▁Mission    ▁in   ▁the  ▁Central  ▁African  ▁Republic  \nlabels           IGN     I-PER  I-PER  I-PER     I-PER     I-PER      I-PER  \npredictions    I-ORG     I-ORG  I-ORG  I-ORG     I-ORG     I-ORG      I-ORG  \nlosses          0.00      6.20   6.40   6.51      6.37      6.44       6.50  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tokens</th>\n      <td>▁United</td>\n      <td>▁Nations</td>\n      <td>▁Multi</td>\n      <td>dimensional</td>\n      <td>▁Integra</td>\n      <td>ted</td>\n      <td>▁Stabil</td>\n      <td>ization</td>\n      <td>▁Mission</td>\n      <td>▁in</td>\n      <td>▁the</td>\n      <td>▁Central</td>\n      <td>▁African</td>\n      <td>▁Republic</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>B-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>IGN</td>\n      <td>I-PER</td>\n      <td>IGN</td>\n      <td>I-PER</td>\n      <td>IGN</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n    </tr>\n    <tr>\n      <th>predictions</th>\n      <td>B-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n    </tr>\n    <tr>\n      <th>losses</th>\n      <td>6.86</td>\n      <td>6.55</td>\n      <td>6.49</td>\n      <td>0.00</td>\n      <td>6.39</td>\n      <td>0.00</td>\n      <td>6.21</td>\n      <td>0.00</td>\n      <td>6.20</td>\n      <td>6.40</td>\n      <td>6.51</td>\n      <td>6.37</td>\n      <td>6.44</td>\n      <td>6.50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":85},{"cell_type":"markdown","source":" It is apparent that something is wrong with the labels of these samples; for example, the United Nations and the\n Central African Republic are each labeled as a person! At the same time, “8. Juli” in the first example is labeled as\n an organization.","metadata":{}},{"cell_type":"code","source":"df_tmp = df.loc[df[\"input_tokens\"].apply(lambda x: u\"\\u2581(\" in x)].head(3).reset_index()\n\nfor i, sample in enumerate(get_sample(df_tmp)):\n    print(f\"With total loss of: {df_tmp['total_loss'][i]}\")\n    display(sample)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:43:17.953019Z","iopub.execute_input":"2025-01-02T23:43:17.953315Z","iopub.status.idle":"2025-01-02T23:43:17.987195Z","shell.execute_reply.started":"2025-01-02T23:43:17.953294Z","shell.execute_reply":"2025-01-02T23:43:17.986474Z"}},"outputs":[{"name":"stdout","text":"With total loss of: 0.05864656902849674\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                 0      1      2             3      4\ntokens        ▁Ham      a     ▁(  ▁Unternehmen     ▁)\nlabels       B-ORG    IGN  I-ORG         I-ORG  I-ORG\npredictions  B-ORG  I-ORG  I-ORG         I-ORG  I-ORG\nlosses        0.01   0.00   0.02          0.01   0.02","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tokens</th>\n      <td>▁Ham</td>\n      <td>a</td>\n      <td>▁(</td>\n      <td>▁Unternehmen</td>\n      <td>▁)</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>B-ORG</td>\n      <td>IGN</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n    </tr>\n    <tr>\n      <th>predictions</th>\n      <td>B-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n    </tr>\n    <tr>\n      <th>losses</th>\n      <td>0.01</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.01</td>\n      <td>0.02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"With total loss of: 0.08168906439095736\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                 0      1      2      3      4      5      6\ntokens       ▁Kesk    kül      a     ▁(  ▁Mart     na     ▁)\nlabels       B-LOC    IGN    IGN  I-LOC  I-LOC    IGN  I-LOC\npredictions  B-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC\nlosses        0.03   0.00   0.00   0.02   0.02   0.00   0.01","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tokens</th>\n      <td>▁Kesk</td>\n      <td>kül</td>\n      <td>a</td>\n      <td>▁(</td>\n      <td>▁Mart</td>\n      <td>na</td>\n      <td>▁)</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>B-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n    </tr>\n    <tr>\n      <th>predictions</th>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n    </tr>\n    <tr>\n      <th>losses</th>\n      <td>0.03</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>0.00</td>\n      <td>0.01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"With total loss of: 0.0780106633901596\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                0      1      2      3      4       5        6      7      8   \\\ntokens        ▁Pik      e  ▁Town   ship     ▁(  ▁Brown  ▁County      ▁      ,   \nlabels       B-LOC    IGN  I-LOC    IGN  I-LOC   I-LOC    I-LOC  I-LOC    IGN   \npredictions  B-LOC  I-LOC  I-LOC  I-LOC  I-LOC   I-LOC    I-LOC  I-LOC  I-LOC   \nlosses        0.01   0.00   0.01   0.00   0.00    0.00     0.00   0.01   0.00   \n\n                9      10  \ntokens       ▁Ohio     ▁)  \nlabels       I-LOC  I-LOC  \npredictions  I-LOC  I-LOC  \nlosses        0.03   0.01  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tokens</th>\n      <td>▁Pik</td>\n      <td>e</td>\n      <td>▁Town</td>\n      <td>ship</td>\n      <td>▁(</td>\n      <td>▁Brown</td>\n      <td>▁County</td>\n      <td>▁</td>\n      <td>,</td>\n      <td>▁Ohio</td>\n      <td>▁)</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>B-LOC</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n    </tr>\n    <tr>\n      <th>predictions</th>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n    </tr>\n    <tr>\n      <th>losses</th>\n      <td>0.01</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>0.00</td>\n      <td>0.03</td>\n      <td>0.01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":87},{"cell_type":"markdown","source":"### Cross-lingual Transfer After Training on German (de)","metadata":{}},{"cell_type":"code","source":"def get_f1_score(trainer, dataset):\n    return trainer.predict(dataset).metrics[\"test_f1\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:00:06.283798Z","iopub.execute_input":"2025-01-03T00:00:06.284231Z","iopub.status.idle":"2025-01-03T00:00:06.289650Z","shell.execute_reply.started":"2025-01-03T00:00:06.284189Z","shell.execute_reply":"2025-01-03T00:00:06.288645Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"f1_scores = defaultdict(dict)\nf1_scores[\"de\"][\"de\"] = get_f1_score(trainer, panx_de_encoded[\"test\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:23:06.880039Z","iopub.execute_input":"2025-01-03T00:23:06.880340Z","iopub.status.idle":"2025-01-03T00:23:17.064363Z","shell.execute_reply.started":"2025-01-03T00:23:06.880317Z","shell.execute_reply":"2025-01-03T00:23:17.063453Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":110},{"cell_type":"code","source":"print(f\"F1-score of [de] model on [de] dataset: {f1_scores['de']['de']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:23:18.253808Z","iopub.execute_input":"2025-01-03T00:23:18.254119Z","iopub.status.idle":"2025-01-03T00:23:18.259635Z","shell.execute_reply.started":"2025-01-03T00:23:18.254092Z","shell.execute_reply":"2025-01-03T00:23:18.258848Z"}},"outputs":[{"name":"stdout","text":"F1-score of [de] model on [de] dataset: 0.868\n","output_type":"stream"}],"execution_count":111},{"cell_type":"code","source":"# testing with french sequence\ntext_fr = \"Jeff Dean est informaticien chez Google en Californie\"\ntag_text(text_fr, trainer.model, xlmr_tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:23:20.295596Z","iopub.execute_input":"2025-01-03T00:23:20.295895Z","iopub.status.idle":"2025-01-03T00:23:20.321385Z","shell.execute_reply.started":"2025-01-03T00:23:20.295870Z","shell.execute_reply":"2025-01-03T00:23:20.320742Z"}},"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"         0      1      2      3     4            5    6      7        8    9   \\\nTokens  <s>  ▁Jeff    ▁De     an  ▁est  ▁informatic  ien  ▁chez  ▁Google  ▁en   \nTags      O  B-PER  I-PER  I-PER     O            O    O      O    B-ORG    O   \n\n           10     11     12    13  \nTokens  ▁Cali    for    nie  </s>  \nTags    B-LOC  I-LOC  I-LOC     O  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jeff</td>\n      <td>▁De</td>\n      <td>an</td>\n      <td>▁est</td>\n      <td>▁informatic</td>\n      <td>ien</td>\n      <td>▁chez</td>\n      <td>▁Google</td>\n      <td>▁en</td>\n      <td>▁Cali</td>\n      <td>for</td>\n      <td>nie</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>O</td>\n      <td>B-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-ORG</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":112},{"cell_type":"code","source":"f1_scores[\"de\"][\"fr\"] = get_f1_score(trainer, panx_fr_encoded[\"test\"])\nprint(f\"F1-score of [de] model on [fr] dataset: {f1_scores['de']['fr']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:23:22.037697Z","iopub.execute_input":"2025-01-03T00:23:22.037989Z","iopub.status.idle":"2025-01-03T00:23:25.160938Z","shell.execute_reply.started":"2025-01-03T00:23:22.037966Z","shell.execute_reply":"2025-01-03T00:23:25.160266Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [de] model on [fr] dataset: 0.696\n","output_type":"stream"}],"execution_count":113},{"cell_type":"code","source":"f1_scores[\"de\"][\"it\"] = get_f1_score(trainer, panx_it_encoded[\"test\"])\nprint(f\"F1-score of [de] model on [it] dataset: {f1_scores['de']['it']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:23:26.823343Z","iopub.execute_input":"2025-01-03T00:23:26.823705Z","iopub.status.idle":"2025-01-03T00:23:27.984431Z","shell.execute_reply.started":"2025-01-03T00:23:26.823662Z","shell.execute_reply":"2025-01-03T00:23:27.983777Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [de] model on [it] dataset: 0.681\n","output_type":"stream"}],"execution_count":114},{"cell_type":"code","source":"f1_scores[\"de\"][\"en\"] = get_f1_score(trainer, panx_en_encoded[\"test\"])\nprint(f\"F1-score of [de] model on [en] dataset: {f1_scores['de']['en']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:23:28.805427Z","iopub.execute_input":"2025-01-03T00:23:28.805840Z","iopub.status.idle":"2025-01-03T00:23:29.637128Z","shell.execute_reply.started":"2025-01-03T00:23:28.805803Z","shell.execute_reply":"2025-01-03T00:23:29.636369Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [de] model on [en] dataset: 0.601\n","output_type":"stream"}],"execution_count":115},{"cell_type":"code","source":"f1_scores[\"de\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:40:52.810861Z","iopub.execute_input":"2025-01-03T00:40:52.811138Z","iopub.status.idle":"2025-01-03T00:40:52.816608Z","shell.execute_reply.started":"2025-01-03T00:40:52.811118Z","shell.execute_reply":"2025-01-03T00:40:52.815828Z"}},"outputs":[{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"{'de': 0.868020304568528,\n 'fr': 0.6958353589369631,\n 'it': 0.6808873720136518,\n 'en': 0.6005665722379604}"},"metadata":{}}],"execution_count":131},{"cell_type":"markdown","source":"### Cross-lingual Transfer After Training on English (en)","metadata":{}},{"cell_type":"code","source":"# for English\naccess_token = \"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\"\nfrom huggingface_hub import login\nlogin(token=access_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:34:35.529206Z","iopub.execute_input":"2025-01-03T00:34:35.529498Z","iopub.status.idle":"2025-01-03T00:34:35.628290Z","shell.execute_reply.started":"2025-01-03T00:34:35.529477Z","shell.execute_reply":"2025-01-03T00:34:35.627407Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":118},{"cell_type":"code","source":"num_epochs = 3\nbatch_size = 16\nlogging_steps = len(panx_en_encoded[\"train\"]) // batch_size\nmodel_name = f\"{xlmr_model_name}-finetuned-panx-en\"\ntraining_args = TrainingArguments(output_dir = model_name, log_level=\"error\", \n                                 num_train_epochs=num_epochs,\n                                 per_device_train_batch_size=batch_size, \n                                 per_device_eval_batch_size=batch_size,\n                                 evaluation_strategy=\"epoch\",\n                                      save_steps=1e6, weight_decay=0.01, disable_tqdm=False,\n                                 logging_steps=logging_steps, push_to_hub=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:34:38.736335Z","iopub.execute_input":"2025-01-03T00:34:38.736722Z","iopub.status.idle":"2025-01-03T00:34:38.766778Z","shell.execute_reply.started":"2025-01-03T00:34:38.736691Z","shell.execute_reply":"2025-01-03T00:34:38.765871Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":119},{"cell_type":"code","source":"trainer_en = Trainer(model_init=model_init, args=training_args, data_collator=data_collator, compute_metrics=compute_metrics,\n                 train_dataset=panx_en_encoded[\"train\"], eval_dataset=panx_en_encoded[\"validation\"],\n                 tokenizer=xlmr_tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:34:43.171934Z","iopub.execute_input":"2025-01-03T00:34:43.172217Z","iopub.status.idle":"2025-01-03T00:34:43.981252Z","shell.execute_reply.started":"2025-01-03T00:34:43.172196Z","shell.execute_reply":"2025-01-03T00:34:43.980597Z"}},"outputs":[],"execution_count":120},{"cell_type":"code","source":"trainer_en.train(), trainer_en.push_to_hub(commit_message=\"Training completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:34:47.459877Z","iopub.execute_input":"2025-01-03T00:34:47.460186Z","iopub.status.idle":"2025-01-03T00:36:01.501899Z","shell.execute_reply.started":"2025-01-03T00:34:47.460164Z","shell.execute_reply":"2025-01-03T00:36:01.501162Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='222' max='222' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [222/222 00:34, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.967900</td>\n      <td>0.505125</td>\n      <td>0.585761</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.461600</td>\n      <td>0.438679</td>\n      <td>0.633718</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.350800</td>\n      <td>0.365907</td>\n      <td>0.682094</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"(TrainOutput(global_step=222, training_loss=0.5889494768134108, metrics={'train_runtime': 34.8603, 'train_samples_per_second': 101.548, 'train_steps_per_second': 6.368, 'total_flos': 58835789295360.0, 'train_loss': 0.5889494768134108, 'epoch': 3.0}),\n CommitInfo(commit_url='https://huggingface.co/Shawki11/xlm-roberta-base-finetuned-panx-en/commit/70407e1d39d378be23bfac238400bf3f3186ec71', commit_message='Training completed!', commit_description='', oid='70407e1d39d378be23bfac238400bf3f3186ec71', pr_url=None, pr_revision=None, pr_num=None))"},"metadata":{}}],"execution_count":121},{"cell_type":"code","source":"f1_scores[\"en\"][\"en\"] = get_f1_score(trainer_en, panx_en_encoded[\"test\"])\nprint(f\"F1-score of [en] model on [en] dataset: {f1_scores['en']['en']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:38:33.654202Z","iopub.execute_input":"2025-01-03T00:38:33.654544Z","iopub.status.idle":"2025-01-03T00:38:34.493838Z","shell.execute_reply.started":"2025-01-03T00:38:33.654514Z","shell.execute_reply":"2025-01-03T00:38:34.493163Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [en] model on [en] dataset: 0.684\n","output_type":"stream"}],"execution_count":124},{"cell_type":"code","source":"f1_scores[\"en\"][\"de\"] = get_f1_score(trainer_en, panx_de_encoded[\"test\"])\nprint(f\"F1-score of [en] model on [de] dataset: {f1_scores['en']['de']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:38:36.584322Z","iopub.execute_input":"2025-01-03T00:38:36.584657Z","iopub.status.idle":"2025-01-03T00:38:46.733824Z","shell.execute_reply.started":"2025-01-03T00:38:36.584631Z","shell.execute_reply":"2025-01-03T00:38:46.733163Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [en] model on [de] dataset: 0.686\n","output_type":"stream"}],"execution_count":125},{"cell_type":"code","source":"f1_scores[\"en\"][\"fr\"] = get_f1_score(trainer_en, panx_fr_encoded[\"test\"])\nprint(f\"F1-score of [en] model on [fr] dataset: {f1_scores['en']['fr']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:39:28.600387Z","iopub.execute_input":"2025-01-03T00:39:28.600732Z","iopub.status.idle":"2025-01-03T00:39:31.722828Z","shell.execute_reply.started":"2025-01-03T00:39:28.600703Z","shell.execute_reply":"2025-01-03T00:39:31.721972Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [en] model on [fr] dataset: 0.670\n","output_type":"stream"}],"execution_count":127},{"cell_type":"code","source":"f1_scores[\"en\"][\"it\"] = get_f1_score(trainer_en, panx_it_encoded[\"test\"])\nprint(f\"F1-score of [en] model on [it] dataset: {f1_scores['en']['it']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:40:14.252227Z","iopub.execute_input":"2025-01-03T00:40:14.252628Z","iopub.status.idle":"2025-01-03T00:40:15.431367Z","shell.execute_reply.started":"2025-01-03T00:40:14.252574Z","shell.execute_reply":"2025-01-03T00:40:15.430583Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [en] model on [it] dataset: 0.691\n","output_type":"stream"}],"execution_count":128},{"cell_type":"code","source":"f1_scores[\"en\"] ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:40:43.925512Z","iopub.execute_input":"2025-01-03T00:40:43.925856Z","iopub.status.idle":"2025-01-03T00:40:43.931097Z","shell.execute_reply.started":"2025-01-03T00:40:43.925831Z","shell.execute_reply":"2025-01-03T00:40:43.930431Z"}},"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":"{'en': 0.6842709529276694,\n 'de': 0.6863819667045807,\n 'fr': 0.6702921068986949,\n 'it': 0.6905263157894737}"},"metadata":{}}],"execution_count":130},{"cell_type":"markdown","source":"### Cross-lingual Transfer After Training on Italian (it)","metadata":{}},{"cell_type":"code","source":"# for Italian\naccess_token = \"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\"\nfrom huggingface_hub import login\nlogin(token=access_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:44:23.448492Z","iopub.execute_input":"2025-01-03T00:44:23.448847Z","iopub.status.idle":"2025-01-03T00:44:23.535293Z","shell.execute_reply.started":"2025-01-03T00:44:23.448821Z","shell.execute_reply":"2025-01-03T00:44:23.534620Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":132},{"cell_type":"code","source":"num_epochs = 3\nbatch_size = 16\nlogging_steps = len(panx_it_encoded[\"train\"]) // batch_size\nmodel_name = f\"{xlmr_model_name}-finetuned-panx-it\"\ntraining_args = TrainingArguments(output_dir = model_name, log_level=\"error\", \n                                 num_train_epochs=num_epochs,\n                                 per_device_train_batch_size=batch_size, \n                                 per_device_eval_batch_size=batch_size,\n                                 evaluation_strategy=\"epoch\",\n                                      save_steps=1e6, weight_decay=0.01, disable_tqdm=False,\n                                 logging_steps=logging_steps, push_to_hub=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:45:16.299786Z","iopub.execute_input":"2025-01-03T00:45:16.300102Z","iopub.status.idle":"2025-01-03T00:45:16.335309Z","shell.execute_reply.started":"2025-01-03T00:45:16.300068Z","shell.execute_reply":"2025-01-03T00:45:16.334540Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":133},{"cell_type":"code","source":"trainer_it = Trainer(model_init=model_init, args=training_args, data_collator=data_collator, compute_metrics=compute_metrics,\n                 train_dataset=panx_it_encoded[\"train\"], eval_dataset=panx_it_encoded[\"validation\"],\n                 tokenizer=xlmr_tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:45:20.988381Z","iopub.execute_input":"2025-01-03T00:45:20.988701Z","iopub.status.idle":"2025-01-03T00:45:21.779793Z","shell.execute_reply.started":"2025-01-03T00:45:20.988676Z","shell.execute_reply":"2025-01-03T00:45:21.779009Z"}},"outputs":[],"execution_count":134},{"cell_type":"code","source":"trainer_it.train(), trainer_it.push_to_hub(commit_message=\"Training completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:45:41.973130Z","iopub.execute_input":"2025-01-03T00:45:41.973425Z","iopub.status.idle":"2025-01-03T00:47:05.074073Z","shell.execute_reply.started":"2025-01-03T00:45:41.973401Z","shell.execute_reply":"2025-01-03T00:47:05.073338Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [315/315 00:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.652100</td>\n      <td>0.296889</td>\n      <td>0.775412</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.256400</td>\n      <td>0.264830</td>\n      <td>0.797380</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.172600</td>\n      <td>0.251780</td>\n      <td>0.820114</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":135,"output_type":"execute_result","data":{"text/plain":"(TrainOutput(global_step=315, training_loss=0.3603487468901135, metrics={'train_runtime': 47.3302, 'train_samples_per_second': 106.486, 'train_steps_per_second': 6.655, 'total_flos': 87833136663552.0, 'train_loss': 0.3603487468901135, 'epoch': 3.0}),\n CommitInfo(commit_url='https://huggingface.co/Shawki11/xlm-roberta-base-finetuned-panx-it/commit/37f1c558146b97432f7a554d04fd54302a2a9233', commit_message='Training completed!', commit_description='', oid='37f1c558146b97432f7a554d04fd54302a2a9233', pr_url=None, pr_revision=None, pr_num=None))"},"metadata":{}}],"execution_count":135},{"cell_type":"code","source":"f1_scores[\"it\"][\"it\"] = get_f1_score(trainer_it, panx_it_encoded[\"test\"])\nprint(f\"F1-score of [it] model on [it] dataset: {f1_scores['it']['it']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:49:29.280083Z","iopub.execute_input":"2025-01-03T00:49:29.280385Z","iopub.status.idle":"2025-01-03T00:49:30.459249Z","shell.execute_reply.started":"2025-01-03T00:49:29.280363Z","shell.execute_reply":"2025-01-03T00:49:30.458394Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [it] model on [it] dataset: 0.807\n","output_type":"stream"}],"execution_count":136},{"cell_type":"code","source":"f1_scores[\"it\"][\"en\"] = get_f1_score(trainer_it, panx_en_encoded[\"test\"])\nprint(f\"F1-score of [it] model on [en] dataset: {f1_scores['it']['en']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:49:35.134880Z","iopub.execute_input":"2025-01-03T00:49:35.135193Z","iopub.status.idle":"2025-01-03T00:49:35.973050Z","shell.execute_reply.started":"2025-01-03T00:49:35.135166Z","shell.execute_reply":"2025-01-03T00:49:35.972364Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [it] model on [en] dataset: 0.596\n","output_type":"stream"}],"execution_count":137},{"cell_type":"code","source":"f1_scores[\"it\"][\"de\"] = get_f1_score(trainer_it, panx_de_encoded[\"test\"])\nprint(f\"F1-score of [it] model on [de] dataset: {f1_scores['it']['de']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:49:38.283449Z","iopub.execute_input":"2025-01-03T00:49:38.283833Z","iopub.status.idle":"2025-01-03T00:49:48.507597Z","shell.execute_reply.started":"2025-01-03T00:49:38.283806Z","shell.execute_reply":"2025-01-03T00:49:48.506654Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [it] model on [de] dataset: 0.709\n","output_type":"stream"}],"execution_count":138},{"cell_type":"code","source":"f1_scores[\"it\"][\"fr\"] = get_f1_score(trainer_it, panx_fr_encoded[\"test\"])\nprint(f\"F1-score of [it] model on [fr] dataset: {f1_scores['it']['fr']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:49:56.425483Z","iopub.execute_input":"2025-01-03T00:49:56.425812Z","iopub.status.idle":"2025-01-03T00:49:59.541442Z","shell.execute_reply.started":"2025-01-03T00:49:56.425788Z","shell.execute_reply":"2025-01-03T00:49:59.540770Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [it] model on [fr] dataset: 0.728\n","output_type":"stream"}],"execution_count":139},{"cell_type":"code","source":"f1_scores[\"it\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:50:09.016408Z","iopub.execute_input":"2025-01-03T00:50:09.016762Z","iopub.status.idle":"2025-01-03T00:50:09.022132Z","shell.execute_reply.started":"2025-01-03T00:50:09.016733Z","shell.execute_reply":"2025-01-03T00:50:09.021320Z"}},"outputs":[{"execution_count":140,"output_type":"execute_result","data":{"text/plain":"{'it': 0.807213396307428,\n 'en': 0.5963954123429819,\n 'de': 0.709366747786465,\n 'fr': 0.7280087186672894}"},"metadata":{}}],"execution_count":140},{"cell_type":"markdown","source":"### Cross-lingual Transfer After Training on French (fr)","metadata":{}},{"cell_type":"code","source":"# for french\naccess_token = \"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\"\nfrom huggingface_hub import login\nlogin(token=access_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:55:13.046970Z","iopub.execute_input":"2025-01-03T00:55:13.047306Z","iopub.status.idle":"2025-01-03T00:55:13.134867Z","shell.execute_reply.started":"2025-01-03T00:55:13.047278Z","shell.execute_reply":"2025-01-03T00:55:13.133914Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":141},{"cell_type":"code","source":"num_epochs = 3\nbatch_size = 16\nlogging_steps = len(panx_fr_encoded[\"train\"]) // batch_size\nmodel_name = f\"{xlmr_model_name}-finetuned-panx-fr\"\ntraining_args = TrainingArguments(output_dir = model_name, log_level=\"error\", \n                                 num_train_epochs=num_epochs,\n                                 per_device_train_batch_size=batch_size, \n                                 per_device_eval_batch_size=batch_size,\n                                 evaluation_strategy=\"epoch\",\n                                      save_steps=1e6, weight_decay=0.01, disable_tqdm=False,\n                                 logging_steps=logging_steps, push_to_hub=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:55:33.882787Z","iopub.execute_input":"2025-01-03T00:55:33.883087Z","iopub.status.idle":"2025-01-03T00:55:33.913282Z","shell.execute_reply.started":"2025-01-03T00:55:33.883065Z","shell.execute_reply":"2025-01-03T00:55:33.912623Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":142},{"cell_type":"code","source":"trainer_fr = Trainer(model_init=model_init, args=training_args, data_collator=data_collator, compute_metrics=compute_metrics,\n                 train_dataset=panx_fr_encoded[\"train\"], eval_dataset=panx_fr_encoded[\"validation\"],\n                 tokenizer=xlmr_tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:56:16.050819Z","iopub.execute_input":"2025-01-03T00:56:16.051114Z","iopub.status.idle":"2025-01-03T00:56:16.526505Z","shell.execute_reply.started":"2025-01-03T00:56:16.051092Z","shell.execute_reply":"2025-01-03T00:56:16.525837Z"}},"outputs":[],"execution_count":144},{"cell_type":"code","source":"trainer_fr.train(), trainer_fr.push_to_hub(commit_message=\"Training completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T01:01:43.616262Z","iopub.execute_input":"2025-01-03T01:01:43.616625Z","iopub.status.idle":"2025-01-03T01:04:13.316497Z","shell.execute_reply.started":"2025-01-03T01:01:43.616594Z","shell.execute_reply":"2025-01-03T01:04:13.315738Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='861' max='861' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [861/861 01:50, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.523700</td>\n      <td>0.311009</td>\n      <td>0.793646</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.260400</td>\n      <td>0.283571</td>\n      <td>0.822736</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.174100</td>\n      <td>0.287094</td>\n      <td>0.843808</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":151,"output_type":"execute_result","data":{"text/plain":"(TrainOutput(global_step=861, training_loss=0.3185522003006298, metrics={'train_runtime': 110.5223, 'train_samples_per_second': 124.319, 'train_steps_per_second': 7.79, 'total_flos': 222310274500608.0, 'train_loss': 0.3185522003006298, 'epoch': 3.0}),\n CommitInfo(commit_url='https://huggingface.co/Shawki11/xlm-roberta-base-finetuned-panx-fr/commit/c5f54b7c59ae103d9f04f8f6036ede5b04912b3b', commit_message='Training completed!', commit_description='', oid='c5f54b7c59ae103d9f04f8f6036ede5b04912b3b', pr_url=None, pr_revision=None, pr_num=None))"},"metadata":{}}],"execution_count":151},{"cell_type":"code","source":"f1_scores[\"fr\"][\"fr\"] = get_f1_score(trainer_fr, panx_fr_encoded[\"test\"])\nprint(f\"F1-score of [fr] model on [fr] dataset: {f1_scores['fr']['fr']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T01:04:58.007146Z","iopub.execute_input":"2025-01-03T01:04:58.007434Z","iopub.status.idle":"2025-01-03T01:05:01.156345Z","shell.execute_reply.started":"2025-01-03T01:04:58.007411Z","shell.execute_reply":"2025-01-03T01:05:01.155555Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [fr] model on [fr] dataset: 0.856\n","output_type":"stream"}],"execution_count":152},{"cell_type":"code","source":"f1_scores[\"fr\"][\"en\"] = get_f1_score(trainer_fr, panx_en_encoded[\"test\"])\nprint(f\"F1-score of [fr] model on [en] dataset: {f1_scores['fr']['en']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T01:05:21.618217Z","iopub.execute_input":"2025-01-03T01:05:21.618510Z","iopub.status.idle":"2025-01-03T01:05:22.470759Z","shell.execute_reply.started":"2025-01-03T01:05:21.618488Z","shell.execute_reply":"2025-01-03T01:05:22.470050Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [fr] model on [en] dataset: 0.595\n","output_type":"stream"}],"execution_count":153},{"cell_type":"code","source":"f1_scores[\"fr\"][\"it\"] = get_f1_score(trainer_fr, panx_it_encoded[\"test\"])\nprint(f\"F1-score of [fr] model on [it] dataset: {f1_scores['fr']['it']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T01:05:56.430469Z","iopub.execute_input":"2025-01-03T01:05:56.430837Z","iopub.status.idle":"2025-01-03T01:05:57.612832Z","shell.execute_reply.started":"2025-01-03T01:05:56.430807Z","shell.execute_reply":"2025-01-03T01:05:57.612125Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [fr] model on [it] dataset: 0.763\n","output_type":"stream"}],"execution_count":154},{"cell_type":"code","source":"f1_scores[\"fr\"][\"de\"] = get_f1_score(trainer_fr, panx_de_encoded[\"test\"])\nprint(f\"F1-score of [fr] model on [de] dataset: {f1_scores['fr']['de']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T01:06:19.159802Z","iopub.execute_input":"2025-01-03T01:06:19.160092Z","iopub.status.idle":"2025-01-03T01:06:29.344788Z","shell.execute_reply.started":"2025-01-03T01:06:19.160072Z","shell.execute_reply":"2025-01-03T01:06:29.344001Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-score of [fr] model on [de] dataset: 0.725\n","output_type":"stream"}],"execution_count":155},{"cell_type":"code","source":"f1_scores[\"fr\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T01:06:36.684332Z","iopub.execute_input":"2025-01-03T01:06:36.684679Z","iopub.status.idle":"2025-01-03T01:06:36.690013Z","shell.execute_reply.started":"2025-01-03T01:06:36.684650Z","shell.execute_reply":"2025-01-03T01:06:36.689393Z"}},"outputs":[{"execution_count":156,"output_type":"execute_result","data":{"text/plain":"{'fr': 0.8556750682292503,\n 'en': 0.5945652173913043,\n 'it': 0.7632600258732213,\n 'de': 0.7252524173299856}"},"metadata":{}}],"execution_count":156},{"cell_type":"markdown","source":"### Summary of Monolingual Fine-Tuning","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(f1_scores)\ndf = df.transpose()\ndf = df.round(3)\ndf.index.name = 'Fine-tuned on'\ndf.columns.name = 'Evaluated on'\nlanguages_order = ['de', 'en', 'it', 'fr']\ndf = df[languages_order].loc[languages_order]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T01:14:23.888679Z","iopub.execute_input":"2025-01-03T01:14:23.888997Z","iopub.status.idle":"2025-01-03T01:14:23.896393Z","shell.execute_reply.started":"2025-01-03T01:14:23.888974Z","shell.execute_reply":"2025-01-03T01:14:23.895739Z"}},"outputs":[],"execution_count":161},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T01:14:27.877045Z","iopub.execute_input":"2025-01-03T01:14:27.877328Z","iopub.status.idle":"2025-01-03T01:14:27.887542Z","shell.execute_reply.started":"2025-01-03T01:14:27.877306Z","shell.execute_reply":"2025-01-03T01:14:27.886647Z"}},"outputs":[{"execution_count":162,"output_type":"execute_result","data":{"text/plain":"Evaluated on      de     en     it     fr\nFine-tuned on                            \nde             0.868  0.601  0.681  0.696\nen             0.686  0.684  0.691  0.670\nit             0.709  0.596  0.807  0.728\nfr             0.725  0.595  0.763  0.856","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Evaluated on</th>\n      <th>de</th>\n      <th>en</th>\n      <th>it</th>\n      <th>fr</th>\n    </tr>\n    <tr>\n      <th>Fine-tuned on</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>de</th>\n      <td>0.868</td>\n      <td>0.601</td>\n      <td>0.681</td>\n      <td>0.696</td>\n    </tr>\n    <tr>\n      <th>en</th>\n      <td>0.686</td>\n      <td>0.684</td>\n      <td>0.691</td>\n      <td>0.670</td>\n    </tr>\n    <tr>\n      <th>it</th>\n      <td>0.709</td>\n      <td>0.596</td>\n      <td>0.807</td>\n      <td>0.728</td>\n    </tr>\n    <tr>\n      <th>fr</th>\n      <td>0.725</td>\n      <td>0.595</td>\n      <td>0.763</td>\n      <td>0.856</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":162}]}